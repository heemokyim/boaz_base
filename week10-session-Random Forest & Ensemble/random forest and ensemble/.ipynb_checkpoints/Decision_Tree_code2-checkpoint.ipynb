{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17장. 의사 결정 나무(Decision Tree) 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## < 1. 기본적인 함수들 설정 >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict # collections 모듈의 Counter와 defaultdict 클래스를 불러들임\n",
    "from functools import partial\n",
    "import math, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ↓↓↓↓ 사용할 예시 데이터를 미리 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inputs는 (dict 형태의 후보자의 다양한 속성 + T/F로 구분되는 label 값)으로 구성됨\n",
    "\n",
    "inputs = [\n",
    "        ({'level':'Senior','lang':'Java','tweets':'no','phd':'no'},   False),\n",
    "        ({'level':'Senior','lang':'Java','tweets':'no','phd':'yes'},  False),\n",
    "        ({'level':'Mid','lang':'Python','tweets':'no','phd':'no'},     True),\n",
    "        ({'level':'Junior','lang':'Python','tweets':'no','phd':'no'},  True),\n",
    "        ({'level':'Junior','lang':'R','tweets':'yes','phd':'no'},      True),\n",
    "        ({'level':'Junior','lang':'R','tweets':'yes','phd':'yes'},    False),\n",
    "        ({'level':'Mid','lang':'R','tweets':'yes','phd':'yes'},        True),\n",
    "        ({'level':'Senior','lang':'Python','tweets':'no','phd':'no'}, False),\n",
    "        ({'level':'Senior','lang':'R','tweets':'yes','phd':'no'},      True),\n",
    "        ({'level':'Junior','lang':'Python','tweets':'yes','phd':'no'}, True),\n",
    "        ({'level':'Senior','lang':'Python','tweets':'yes','phd':'yes'},True),\n",
    "        ({'level':'Mid','lang':'Python','tweets':'no','phd':'yes'},    True),\n",
    "        ({'level':'Mid','lang':'Java','tweets':'yes','phd':'no'},      True),\n",
    "        ({'level':'Junior','lang':'Python','tweets':'no','phd':'yes'},False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'lang': 'Java', 'level': 'Senior', 'phd': 'no', 'tweets': 'no'}, False),\n",
       " ({'lang': 'Java', 'level': 'Senior', 'phd': 'yes', 'tweets': 'no'}, False),\n",
       " ({'lang': 'Python', 'level': 'Mid', 'phd': 'no', 'tweets': 'no'}, True),\n",
       " ({'lang': 'Python', 'level': 'Junior', 'phd': 'no', 'tweets': 'no'}, True),\n",
       " ({'lang': 'R', 'level': 'Junior', 'phd': 'no', 'tweets': 'yes'}, True),\n",
       " ({'lang': 'R', 'level': 'Junior', 'phd': 'yes', 'tweets': 'yes'}, False),\n",
       " ({'lang': 'R', 'level': 'Mid', 'phd': 'yes', 'tweets': 'yes'}, True),\n",
       " ({'lang': 'Python', 'level': 'Senior', 'phd': 'no', 'tweets': 'no'}, False),\n",
       " ({'lang': 'R', 'level': 'Senior', 'phd': 'no', 'tweets': 'yes'}, True),\n",
       " ({'lang': 'Python', 'level': 'Junior', 'phd': 'no', 'tweets': 'yes'}, True),\n",
       " ({'lang': 'Python', 'level': 'Senior', 'phd': 'yes', 'tweets': 'yes'}, True),\n",
       " ({'lang': 'Python', 'level': 'Mid', 'phd': 'yes', 'tweets': 'no'}, True),\n",
       " ({'lang': 'Java', 'level': 'Mid', 'phd': 'no', 'tweets': 'yes'}, True),\n",
       " ({'lang': 'Python', 'level': 'Junior', 'phd': 'yes', 'tweets': 'no'}, False)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pg 206"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스에 속할 확률을 입력하면, 엔트로피를 계산하라.  /데이터셋 전체에 대한 엔트로피\n",
    "# class_probabilities: 확률값 데이터셋\n",
    "# 'if p'에서 p=0인 경우는 제외된다. (if문은 그 값이 참일 때, 즉 p !- 0 일 때만 다음 순서가 진행되므로)\n",
    "\n",
    "def entropy(class_probabilities): \n",
    "    return sum(-p * math.log(p, 2) for p in class_probabilities if p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 엔트로피 공식에서 나오는 p를 구하고 있음\n",
    "# collections 모듈의 Counter 클래스: 리스트 내의 요소가 몇 번이나 반복되었는지 카운트를 해야 하는 경우 사용\n",
    "# Counter는 사전(dict) 클래스의 하위 클래스로, 리스트나 튜플에서 각 데이터가 등장한 횟수를 사전 형식으로 돌려준다. \n",
    "\n",
    "def class_probabilities(labels):\n",
    "    total_count = len(labels)   # len(list)라는 method는 [list]에 있는 요소의 수를 return한다.\n",
    "    \n",
    "    return [count / total_count # 엔트로피 공식에서 나오는 p를 구함\n",
    "            for count in Counter(labels).values()] \n",
    "    # .values: 레이블 별로 해당 레이블을 가진 데이터 포인트의 갯수를 return함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 위 두 cell에서 정의한 함수들을 이용하여 입력된 데이터셋의 엔트로피를 구하는 함수\n",
    "\n",
    "def data_entropy(labeled_data):\n",
    "    labels = [label for _, label in labeled_data] # labels라는 list를 생성. \n",
    "# '_'는 앞서 입력한 inputs에서 우리가 관심있는 것은 label이므로, 이 코드에서 가져다 쓰지 않는 다른 속성값들 dict를 _로 표현한 것.\n",
    "    probabilities = class_probabilities(labels)  \n",
    "   \n",
    "    return entropy(probabilities) # 데이터셋 전체에 대한 엔트로피 값을 리턴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pg 207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 파티션(partition) 엔트로피를 통해 전체 엔트로피 구하기\n",
    "\n",
    "def partition_entropy(subsets):     # subsets는 subset이라는 list들의 list\n",
    "    total_count = sum(len(subset) for subset in subsets)  # 각 subset들에 포함된 데이터 포인트의 갯수들의 합 = 총 갯수\n",
    "    \n",
    "    return sum( data_entropy(subset) * len(subset) / total_count for subset in subsets )\n",
    "               # data_entropy(subset)는 H(S)를, len(subset) / total_count는 q를(각 파티션별 차지하는 비율)을 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## < 2. 예제 데이터로 의사 결정 나무(Decision Tree) 만들어보기 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1. 파티션(partition) 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# key값이 같은 것들끼리 묶어준다\n",
    "\n",
    "def group_by(items, key_fn):\n",
    "    \"\"\"returns a defaultdict(list), where each input item is in the list whose key is key_fn(item)\"\"\"\n",
    "    \"\"\"키 값이 key_fn(item)인 item들로 이루어진 list의 defaultdict(list)를 리턴\"\"\"\n",
    "    groups = defaultdict(list)\n",
    "    # collections 모듈의 defaultdict 클래스는 만약 키 값이 없더라도 키 값을 새로 생성해서 append 하게 해 줌.\n",
    "    \n",
    "    for item in items:\n",
    "        key = key_fn(item)\n",
    "        groups[key].append(item) # item들을 groups의 key값들로 이루어진 list에 계속 추가.\n",
    "\n",
    "    return groups # 최종으로 return하는 건 list 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 속성에 따라 입력된 데이터셋 분류하기\n",
    "\n",
    "def partition_by(inputs, attribute):\n",
    "    \"\"\"returns a dict of inputs partitioned by the attribute/ each input is a pair (attribute_dict, label)\"\"\"\n",
    "    \n",
    "    return group_by(inputs, lambda x: x[0][attribute])\n",
    "    # 바로 위 셀에서 key_fn값에 lambda x를 주는데, 여기서 lambda x는 특정 attribute(속성)의 값을 불러온 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'Junior': [({'lang': 'Python',\n",
       "                'level': 'Junior',\n",
       "                'phd': 'no',\n",
       "                'tweets': 'no'},\n",
       "               True),\n",
       "              ({'lang': 'R', 'level': 'Junior', 'phd': 'no', 'tweets': 'yes'},\n",
       "               True),\n",
       "              ({'lang': 'R', 'level': 'Junior', 'phd': 'yes', 'tweets': 'yes'},\n",
       "               False),\n",
       "              ({'lang': 'Python',\n",
       "                'level': 'Junior',\n",
       "                'phd': 'no',\n",
       "                'tweets': 'yes'},\n",
       "               True),\n",
       "              ({'lang': 'Python',\n",
       "                'level': 'Junior',\n",
       "                'phd': 'yes',\n",
       "                'tweets': 'no'},\n",
       "               False)],\n",
       "             'Mid': [({'lang': 'Python',\n",
       "                'level': 'Mid',\n",
       "                'phd': 'no',\n",
       "                'tweets': 'no'},\n",
       "               True),\n",
       "              ({'lang': 'R', 'level': 'Mid', 'phd': 'yes', 'tweets': 'yes'},\n",
       "               True),\n",
       "              ({'lang': 'Python',\n",
       "                'level': 'Mid',\n",
       "                'phd': 'yes',\n",
       "                'tweets': 'no'},\n",
       "               True),\n",
       "              ({'lang': 'Java', 'level': 'Mid', 'phd': 'no', 'tweets': 'yes'},\n",
       "               True)],\n",
       "             'Senior': [({'lang': 'Java',\n",
       "                'level': 'Senior',\n",
       "                'phd': 'no',\n",
       "                'tweets': 'no'},\n",
       "               False),\n",
       "              ({'lang': 'Java',\n",
       "                'level': 'Senior',\n",
       "                'phd': 'yes',\n",
       "                'tweets': 'no'},\n",
       "               False),\n",
       "              ({'lang': 'Python',\n",
       "                'level': 'Senior',\n",
       "                'phd': 'no',\n",
       "                'tweets': 'no'},\n",
       "               False),\n",
       "              ({'lang': 'R', 'level': 'Senior', 'phd': 'no', 'tweets': 'yes'},\n",
       "               True),\n",
       "              ({'lang': 'Python',\n",
       "                'level': 'Senior',\n",
       "                'phd': 'yes',\n",
       "                'tweets': 'yes'},\n",
       "               True)]})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_by(inputs, 'level')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ㄴ여기서 잠깐! 람다(lambda)식 복습: https://wikidocs.net/64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. 가장 낮은 엔트로피를 반환하는, 즉 데이터 포인트가 제일 제각각 분류되는 파티션(partition) 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 주어진 파티션에 각각에 대응되는 엔트로피를 계산\n",
    "\n",
    "def partition_entropy_by(inputs,attribute):\n",
    "    partitions = partition_by(inputs, attribute)\n",
    "\n",
    "    return partition_entropy(partitions.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 0.6935361388961919\n",
      "lang 0.8601317128547441\n",
      "tweets 0.7884504573082896\n",
      "phd 0.8921589282623617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터셋에 대해 엔트로피를 최소화하는 파티션(partition) 찾기\n",
    "\n",
    "for key in ['level','lang','tweets','phd']:\n",
    "    print(key, partition_entropy_by(inputs, key))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ㄴ 'level', 즉 직급에 대한 파티션의 엔트로피가 최솟값이므로, 이를 decision tree의 맨 꼭대기에 있는 root node로 삼는다. 그 이후는 'level'별로 분류되는 데이터 포인트들이 다른 속성(attribute)별로는 어떻게 분류되는지를 보고 또 다음 노드를 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang 0.4\n",
      "tweets 0.0\n",
      "phd 0.9509775004326938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "senior_inputs = [(input, label) for input, label in inputs if input[\"level\"] == \"Senior\"]\n",
    "# 만약 직급이 senior라면, inputs라는 list에 있는 해당 사람의 label과 input 값으로 senior_inputs를 만듦\n",
    "\n",
    "for key in ['lang', 'tweets', 'phd']: print(key, partition_entropy_by(senior_inputs, key))\n",
    "# 직급이 senior인 사람들을 나머지 속성(lang, tweets, phd)에 따라 분류해서 속성별 파티션을 만들고, 각각에 대한 엔트로피를 구함\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3. 의사 결정 나무(Decision Tree)로 주어진 입력값 inputs 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_tree_id3(inputs, split_candidates=None):\n",
    "\n",
    "    # 만약 첫 번째로 파티셔닝 하는 단계라면, 모든 변수가 파티셔닝 기준의 후보가 된다.\n",
    "    if split_candidates is None:\n",
    "        split_candidates = inputs[0][0].keys()\n",
    "\n",
    "    # inputs에서 True와 False의 갯수를 센다.\n",
    "    num_inputs = len(inputs)  # 총 입력값 갯수를 센다.\n",
    "    num_trues = len([label for item, label in inputs if label])  #label 값이 True인 입력값에 한해 label 갯수를 센다.\n",
    "    num_falses = num_inputs - num_trues  # (총 입력값 갯수) - (label 값이 True인 입력값 갯수)\n",
    "\n",
    "    if num_trues == 0:                  # 만약 True가 없다면\n",
    "        return False                    # False인 잎을 return\n",
    "\n",
    "    if num_falses == 0:                 # 만약 False가 없다면\n",
    "        return True                     # True인 잎을 return\n",
    "\n",
    "    if not split_candidates:            # 파티셔닝 기준의 후보가 될 만한 속성(attribute)이 없다면\n",
    "        return num_trues >= num_falses  # 다수결(majority voting)로 결과를 결정\n",
    "\n",
    "    \n",
    "    # 아니면 가장 적절한 속성(attribute)에 따라 파티셔닝을 한다.\n",
    "    # 가장 적절한 속성이란? 엔트로피가 최소가 되는 = 불확실도가 가장 낮은 = 입력값들이 제일 제각각 분류되는 속성\n",
    "    best_attribute = min(split_candidates, key=partial(partition_entropy_by, inputs))\n",
    "    \n",
    "    partitions = partition_by(inputs, best_attribute)\n",
    "    new_candidates = [a for a in split_candidates if a != best_attribute]\n",
    "\n",
    "\n",
    "    # 재귀적(recursively)으로 subtree를 구축한다.\n",
    "    # 재귀적이라고 표현한 이유: build_tree_id3라는 함수를 정의하는 중인데, 해당 함수 내에서 또 해당 함수를 호출하기 때문!\n",
    "    subtrees = { attribute : build_tree_id3(subset, new_candidates)\n",
    "                 for attribute, subset in partitions.items() }\n",
    "\n",
    "    subtrees[None] = num_trues > num_falses # default case(기본값)\n",
    "\n",
    "    return (best_attribute, subtrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -------- BUILDING THE TREE -------- \n",
      "('level', {'Senior': ('tweets', {'no': False, 'yes': True, None: False}), 'Mid': True, 'Junior': ('phd', {'no': True, 'yes': False, None: True}), None: True})\n"
     ]
    }
   ],
   "source": [
    "print(\" -------- BUILDING THE TREE -------- \")\n",
    "\n",
    "tree = build_tree_id3(inputs)\n",
    "\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4. 실제로 분류해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 의사 결정 나무(Decision Tree)로 주어진 입력값을 분류하기 위한 함수 classify\n",
    "\n",
    "def classify(tree, input):\n",
    "    # 잎 노드이면(데이터 포인트가 어디에 분류되는지 가늠할 수 있으면) 값을 반환하고\n",
    "    if tree in [True, False]:\n",
    "        return tree\n",
    "\n",
    "    # 그렇지 않으면 정확한 subtree를 찾아라(데이터의 변수로 다음 파티션을 나누자)\n",
    "    attribute, subtree_dict = tree\n",
    "\n",
    "    subtree_key = input.get(attribute)  # None if input is missing attribute\n",
    "\n",
    "    if subtree_key not in subtree_dict: # if no subtree for key,\n",
    "        subtree_key = None              # we'll use the None subtree\n",
    "\n",
    "    subtree = subtree_dict[subtree_key] # choose the appropriate subtree\n",
    "\n",
    "    return classify(subtree, input)     # and use it to classify the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Junior / Java / tweets / no phd True\n"
     ]
    }
   ],
   "source": [
    "print(\"Junior / Java / tweets / no phd\", classify(tree, \n",
    "        { \"level\" : \"Junior\", \"lang\" : \"Java\", \"tweets\" : \"yes\", \"phd\" : \"no\"}) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Junior / Java / tweets / phd False\n"
     ]
    }
   ],
   "source": [
    "print(\"Junior / Java / tweets / phd\", classify(tree,\n",
    "        { \"level\" : \"Junior\", \"lang\" : \"Java\", \"tweets\" : \"yes\", \"phd\" : \"yes\"} ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intern True\n",
      "Senior False\n"
     ]
    }
   ],
   "source": [
    "# classify 함수에서 속성 값이 inputs에 있는 속성 중 하나에 해당되지 않으면 None 값을 주라고 설정했기 때문에 아래 예도 분류가 가능.\n",
    "\n",
    "print(\"Intern\", classify(tree, { \"level\" : \"Intern\" } ))\n",
    "print(\"Senior\", classify(tree, { \"level\" : \"Senior\" } ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ㄴ 실제로는 이렇게 나무의 예측 오류가 0이어서는 안 된다. 이게 바로 과적합(overfitting)이 일어난 경우이다. 하지만 예제 데이터의 수가 너무 적으므로 굳이 가지치기(pruning)는 하지 않고 넘어간다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
